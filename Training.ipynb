{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d14bb5",
   "metadata": {},
   "source": [
    "#### Before we start\n",
    "Let's make sure that we have access to GPU. We can use nvidia-smi command to do that. In case of any problems navigate to Edit -> Notebook settings -> Hardware accelerator, set it to GPU, and then click Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3303dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 28 18:13:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 577.00                 Driver Version: 577.00         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P8              3W /   60W |      67MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            6348    C+G   ...s\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A           32920      C   ...cord\\app-1.0.9204\\Discord.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d95a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\WebObstacleDetection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7dccd",
   "metadata": {},
   "source": [
    "#### Install Cuda Torch for RTX 3050\n",
    "ONLY FOR RTX 3050:\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00fcb9",
   "metadata": {},
   "source": [
    "#### Install YOLO\n",
    "YOLO can be installed in two ways - from the source and via pip. This is because it is the first iteration of YOLO to have an official package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff9298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.170  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Setup complete  (20 CPUs, 31.7 GB RAM, 1168.8/1352.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "# pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a3b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddeec560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())         # True\n",
    "print(torch.cuda.get_device_name(0))     # Harusnya \"NVIDIA GeForce RTX 3050\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f514d",
   "metadata": {},
   "source": [
    "#### CLI Basics\n",
    "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25abee",
   "metadata": {},
   "source": [
    "#### Check PyTorch & Torchvision\n",
    "PyTorch 2.5.x → torchvision 0.20.x\\\n",
    "PyTorch 2.4.x → torchvision 0.19.x\\\n",
    "PyTorch 2.3.x → torchvision 0.18.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a660e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "Torchvision version: 0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc10a8",
   "metadata": {},
   "source": [
    "#### Main Code (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0687b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.188 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.170  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=.\\data\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5su.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov5su_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\yolov5su_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      "YOLOv5s summary: 153 layers, 9,123,740 parameters, 9,123,724 gradients, 24.0 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 52.712.4 MB/s, size: 17.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\KULIAH\\SP-25\\Comvis\\FinalProj\\WebObstacleDetection\\data\\train\\labels.cache... 2484 images, 21 backgrounds, 0 corrupt: 100%|██████████| 2484/2484 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 143.736.3 MB/s, size: 22.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\KULIAH\\SP-25\\Comvis\\FinalProj\\WebObstacleDetection\\data\\valid\\labels.cache... 251 images, 2 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolov5su_1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov5su_1\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.29G      1.264      1.521      1.258         26        320: 100%|██████████| 156/156 [00:49<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.533      0.549      0.548      0.309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      1.29G      1.344      1.371       1.29         11        320: 100%|██████████| 156/156 [00:43<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.557      0.535      0.539      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      1.29G        1.4      1.458       1.34         16        320: 100%|██████████| 156/156 [00:41<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.578        0.5      0.539      0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      1.29G      1.393      1.383      1.323         12        320: 100%|██████████| 156/156 [00:46<00:00,  3.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.56      0.502      0.535      0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      1.29G      1.336        1.3      1.299         14        320: 100%|██████████| 156/156 [00:39<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.819      0.506      0.627      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      1.29G      1.288      1.233       1.27         14        320: 100%|██████████| 156/156 [00:38<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.68      0.581      0.622      0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      1.29G      1.252      1.169       1.24          9        320: 100%|██████████| 156/156 [00:33<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.751       0.54      0.636       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      1.29G      1.221      1.124       1.23         12        320: 100%|██████████| 156/156 [00:32<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.635      0.635      0.659      0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      1.29G      1.218       1.13      1.236         15        320: 100%|██████████| 156/156 [00:37<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.742      0.586      0.655       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      1.29G       1.17      1.064      1.207         11        320: 100%|██████████| 156/156 [00:38<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.666      0.631       0.67      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      1.29G       1.18      1.066      1.209         11        320: 100%|██████████| 156/156 [00:37<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.74        0.6      0.678      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100       1.3G      1.127     0.9954      1.174         27        320: 100%|██████████| 156/156 [00:36<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.724      0.634      0.694      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100       1.3G      1.111     0.9654      1.174         14        320: 100%|██████████| 156/156 [00:33<00:00,  4.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.715      0.655      0.706       0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100       1.3G      1.105      0.976      1.169         10        320: 100%|██████████| 156/156 [00:33<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.651      0.639      0.667      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100       1.3G      1.099     0.9362      1.162         25        320: 100%|██████████| 156/156 [00:39<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.715       0.66      0.687      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100       1.3G      1.065     0.9048      1.147         12        320: 100%|██████████| 156/156 [00:39<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.72      0.657       0.71      0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100       1.3G      1.061      0.909      1.144         13        320: 100%|██████████| 156/156 [00:37<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.778      0.638      0.705      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100       1.3G      1.066     0.8943      1.141         15        320: 100%|██████████| 156/156 [00:36<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.711      0.657      0.719      0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100       1.3G      1.046     0.8728      1.133         14        320: 100%|██████████| 156/156 [00:33<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.764      0.688      0.736      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100       1.3G      1.026     0.8515      1.122         25        320: 100%|██████████| 156/156 [00:34<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.757      0.631      0.701       0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100       1.3G      1.018     0.8353      1.118         12        320: 100%|██████████| 156/156 [00:41<00:00,  3.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.692      0.689      0.715      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100       1.3G      1.002     0.8286      1.115         20        320: 100%|██████████| 156/156 [00:38<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.764      0.693      0.747      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100       1.3G          1     0.8244      1.114         17        320: 100%|██████████| 156/156 [00:37<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.741       0.67      0.735      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100       1.3G     0.9885     0.8094      1.107          8        320: 100%|██████████| 156/156 [00:25<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.734      0.688      0.738      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100       1.3G     0.9823     0.7819       1.09         25        320: 100%|██████████| 156/156 [00:32<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.75       0.67      0.729      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100       1.3G      0.972     0.7679      1.098         16        320: 100%|██████████| 156/156 [00:33<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.782      0.674      0.748      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100       1.3G     0.9507      0.767      1.094         11        320: 100%|██████████| 156/156 [00:36<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.797      0.686      0.741      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100       1.3G     0.9585     0.7559      1.087         20        320: 100%|██████████| 156/156 [00:35<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.791       0.67      0.735      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100       1.3G     0.9463     0.7472      1.081         18        320: 100%|██████████| 156/156 [00:37<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.774      0.662      0.733      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100       1.3G     0.9351     0.7455      1.081         14        320: 100%|██████████| 156/156 [00:35<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.789       0.67      0.736      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100       1.3G     0.9388     0.7234      1.078         13        320: 100%|██████████| 156/156 [00:33<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.762      0.702      0.741      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100       1.3G     0.8984     0.6976      1.059         19        320: 100%|██████████| 156/156 [00:33<00:00,  4.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.797      0.698      0.761      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100       1.3G     0.9154     0.7118      1.068         17        320: 100%|██████████| 156/156 [00:37<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.714      0.725      0.748      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100       1.3G     0.8924      0.688      1.056         18        320: 100%|██████████| 156/156 [00:36<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.755      0.699      0.753      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100       1.3G     0.8897     0.6862      1.055         17        320: 100%|██████████| 156/156 [00:35<00:00,  4.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.78      0.691      0.748      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100       1.3G     0.8891      0.669       1.05         20        320: 100%|██████████| 156/156 [00:35<00:00,  4.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.783      0.685      0.748      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100       1.3G     0.8937     0.6661      1.049         20        320: 100%|██████████| 156/156 [00:32<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.754      0.693       0.74      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100       1.3G     0.8725     0.6594       1.04         15        320: 100%|██████████| 156/156 [00:30<00:00,  5.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.803      0.704       0.77      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100       1.3G     0.8698     0.6632      1.051         23        320: 100%|██████████| 156/156 [00:17<00:00,  8.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.799      0.706      0.761      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100       1.3G     0.8529     0.6438      1.041         22        320: 100%|██████████| 156/156 [00:17<00:00,  8.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.81      0.696      0.758      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100       1.3G     0.8494      0.627      1.031         13        320: 100%|██████████| 156/156 [00:17<00:00,  8.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.801      0.694       0.76      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100       1.3G      0.844     0.6246      1.039         10        320: 100%|██████████| 156/156 [00:17<00:00,  8.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.845      0.672       0.75      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100       1.3G     0.8362     0.6257      1.032         19        320: 100%|██████████| 156/156 [00:17<00:00,  8.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.779      0.725      0.758      0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100       1.3G      0.839     0.6243      1.026         19        320: 100%|██████████| 156/156 [00:17<00:00,  8.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.815      0.707      0.764      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100       1.3G     0.8143     0.6054      1.026         10        320: 100%|██████████| 156/156 [00:17<00:00,  8.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.748      0.713      0.759      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100       1.3G     0.8262     0.6121       1.03         11        320: 100%|██████████| 156/156 [00:17<00:00,  8.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.826      0.702      0.765      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100       1.3G     0.8281     0.6099      1.022         26        320: 100%|██████████| 156/156 [00:17<00:00,  8.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.777      0.716      0.766       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100       1.3G     0.8154     0.6032      1.017         14        320: 100%|██████████| 156/156 [00:17<00:00,  8.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.812      0.701      0.758      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100       1.3G     0.8074      0.593      1.019         24        320: 100%|██████████| 156/156 [00:17<00:00,  8.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.758      0.726       0.76       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100       1.3G     0.8017     0.5893      1.017         20        320: 100%|██████████| 156/156 [00:17<00:00,  8.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.785      0.715      0.764      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100       1.3G     0.7773     0.5809       1.01         13        320: 100%|██████████| 156/156 [00:17<00:00,  8.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.811      0.711      0.764      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100       1.3G     0.8022     0.5898      1.017         16        320: 100%|██████████| 156/156 [00:17<00:00,  8.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.789      0.696      0.762      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100       1.3G     0.7885     0.5713      1.012         22        320: 100%|██████████| 156/156 [00:17<00:00,  8.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.827      0.709      0.763      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100       1.3G     0.7574     0.5579      1.004         17        320: 100%|██████████| 156/156 [00:17<00:00,  8.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.785        0.7      0.759      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100       1.3G     0.7681     0.5572      1.001         14        320: 100%|██████████| 156/156 [00:17<00:00,  8.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.851      0.672      0.757      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100       1.3G     0.7562     0.5424     0.9936         15        320: 100%|██████████| 156/156 [00:17<00:00,  8.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.814      0.684      0.758      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100       1.3G     0.7492      0.542     0.9944         12        320: 100%|██████████| 156/156 [00:18<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.826      0.693      0.766      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100       1.3G     0.7481     0.5375     0.9965         11        320: 100%|██████████| 156/156 [00:18<00:00,  8.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.845      0.683       0.76      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100       1.3G     0.7446     0.5342     0.9945         13        320: 100%|██████████| 156/156 [00:18<00:00,  8.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.862      0.686      0.765      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100       1.3G     0.7453     0.5383      0.991         11        320: 100%|██████████| 156/156 [00:17<00:00,  8.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.813      0.712      0.778      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100       1.3G     0.7352     0.5338     0.9876          7        320: 100%|██████████| 156/156 [00:18<00:00,  8.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.832      0.703      0.768      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100       1.3G     0.7323     0.5291      0.984         10        320: 100%|██████████| 156/156 [00:18<00:00,  8.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.789      0.711      0.771      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100       1.3G     0.7354     0.5349     0.9933          9        320: 100%|██████████| 156/156 [00:18<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.843      0.693      0.762      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100       1.3G     0.7125     0.5111     0.9798         14        320: 100%|██████████| 156/156 [00:18<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.813      0.694      0.764      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100       1.3G       0.71     0.5076     0.9821         19        320: 100%|██████████| 156/156 [00:18<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.786      0.708      0.748      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100       1.3G     0.7097     0.5007     0.9763          9        320: 100%|██████████| 156/156 [00:18<00:00,  8.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.745      0.734      0.772      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100       1.3G     0.7053     0.5086     0.9799         31        320: 100%|██████████| 156/156 [00:18<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.842        0.7      0.772      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100       1.3G     0.7017     0.4938     0.9739         18        320: 100%|██████████| 156/156 [00:17<00:00,  8.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.834      0.693      0.755      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100       1.3G     0.6935     0.4903     0.9702         14        320: 100%|██████████| 156/156 [00:18<00:00,  8.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.805      0.711      0.768       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100       1.3G     0.6889      0.487     0.9744         12        320: 100%|██████████| 156/156 [00:18<00:00,  8.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.832      0.687      0.764      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100       1.3G     0.6971     0.4986     0.9748         14        320: 100%|██████████| 156/156 [00:17<00:00,  8.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.794      0.721      0.762      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100       1.3G     0.6923     0.4832     0.9708         17        320: 100%|██████████| 156/156 [00:17<00:00,  8.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.803       0.71      0.767      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100       1.3G     0.6749     0.4763     0.9626         12        320: 100%|██████████| 156/156 [00:18<00:00,  8.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.811      0.714      0.774      0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100       1.3G     0.6801     0.4797     0.9664         13        320: 100%|██████████| 156/156 [00:18<00:00,  8.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.827      0.704      0.764      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100       1.3G     0.6749     0.4712     0.9644          7        320: 100%|██████████| 156/156 [00:18<00:00,  8.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.798      0.714      0.761      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100       1.3G      0.654     0.4635     0.9609         11        320: 100%|██████████| 156/156 [00:17<00:00,  8.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.791        0.7      0.758      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100       1.3G     0.6517     0.4549     0.9551         20        320: 100%|██████████| 156/156 [00:17<00:00,  8.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.787      0.716      0.767      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100       1.3G     0.6596     0.4603     0.9552         18        320: 100%|██████████| 156/156 [00:17<00:00,  8.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.853      0.697       0.77      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100       1.3G     0.6568     0.4535     0.9558         18        320: 100%|██████████| 156/156 [00:17<00:00,  8.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.849      0.704      0.767      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100       1.3G     0.6527     0.4571      0.954         25        320: 100%|██████████| 156/156 [00:17<00:00,  8.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.827      0.709      0.769      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100       1.3G     0.6412      0.446      0.954         11        320: 100%|██████████| 156/156 [00:17<00:00,  8.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.839      0.696      0.766      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100       1.3G      0.641     0.4532     0.9549         12        320: 100%|██████████| 156/156 [00:18<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.826      0.701      0.769      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100       1.3G     0.6215      0.436     0.9476         11        320: 100%|██████████| 156/156 [00:18<00:00,  8.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695       0.82      0.697      0.767      0.522\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 73, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "83 epochs completed in 0.680 hours.\n",
      "Optimizer stripped from runs\\detect\\yolov5su_1\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from runs\\detect\\yolov5su_1\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating runs\\detect\\yolov5su_1\\weights\\best.pt...\n",
      "Ultralytics 8.3.170  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,113,084 parameters, 0 gradients, 23.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.812      0.713      0.775      0.531\n",
      "                 Mobil        114        248        0.8       0.79       0.83      0.565\n",
      "                 Motor         49         79      0.783      0.861      0.887      0.597\n",
      "                 Orang         70        195      0.776      0.364      0.467      0.238\n",
      "                  Truk        144        173       0.89      0.839      0.915      0.725\n",
      "Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\yolov5su_1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a Model\n",
    "model = YOLO(\"yolov5su.pt\") #  build a new model from scratch\n",
    "\n",
    "# Use the model\n",
    "results = model.train(\n",
    "    data=\".\\data\\data.yaml\", \n",
    "    epochs=100,\n",
    "    imgsz=320, \n",
    "    patience=10, \n",
    "    verbose=True,\n",
    "\n",
    "    project=\"runs/detect\",\n",
    "    name=\"yolov5su_1\"\n",
    ") # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225fbdc",
   "metadata": {},
   "source": [
    "#### Main Code (Demo webcam implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load model\n",
    "model = YOLO(\"./models/suBest3.pt\")  # load a custom model\n",
    "\n",
    "# Gunakan webcam sebagai source (source=0)\n",
    "results = model.predict(source=0, show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21620ed4",
   "metadata": {},
   "source": [
    "#### Main Code (Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# url = ''\n",
    "cam = cv2.VideoCapture(0) # Ambil atau gunakan kamera ke-0\n",
    "\n",
    "if not cam.isOpened():\n",
    "    print(\"Tidak dapat membuka webcam\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Baca frame dari webcam\n",
    "    ret, frame = cam.read()\n",
    "    H, W, _ = frame.shape # ???\n",
    "    if not ret:\n",
    "        print(\"Gagal membaca frame dari webcam\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fab3c",
   "metadata": {},
   "source": [
    "#### Evaluation Reports (YOLO Metrics)\n",
    "**Evaluation report metrics consist:**\n",
    "> **Precision**\\\n",
    "> **Recall**\\\n",
    "> **F1-Score**\\\n",
    "> **mAP50**\\\n",
    "> **mAP50-95**\n",
    "\n",
    "There are no metrics such as **Accuracy** and **F1-Score** in **YOLO Metrics**\n",
    "\n",
    "The results would be different from the manual evaluation metrics that has been made below. It was due to the fact that both had a different metrics.\n",
    "> YOLO metrics using **Object Detection metrics** (mAP, precision/recall) for the bounding boxes\\\n",
    "> Manual evaluation was using **Classification metrics** (Accuracy, Precision, Recall, F1-Score, and Support) for Class Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28c3a9",
   "metadata": {},
   "source": [
    "pip install scikit-learn\n",
    "pip install numpy\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e38bad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.170  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,113,084 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 257.992.5 MB/s, size: 22.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\KULIAH\\SP-25\\Comvis\\FinalProj\\WebObstacleDetection\\data\\valid\\labels.cache... 251 images, 2 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:01<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.812      0.714      0.774       0.53\n",
      "                 Mobil        114        248        0.8       0.79       0.83      0.564\n",
      "                 Motor         49         79      0.782      0.861      0.887      0.596\n",
      "                 Orang         70        195      0.777      0.364      0.465      0.235\n",
      "                  Truk        144        173       0.89      0.839      0.915      0.727\n",
      "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===== EVALUASI MENGGUNAKAN BEST MODEL =====\n",
    "# Load best model\n",
    "best_model = YOLO(\"./runs/detect/yolov5su_1/weights/suBest4.pt\")\n",
    "\n",
    "# Evaluate\n",
    "val_results = best_model.val(data=\"./data/data.yaml\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c286ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Output directory: ./runs/detect/yolov5su_1/\n",
      "🤖 Model: ./runs/detect/yolov5su_1/weights/suBest3.pt\n",
      "📊 Data config: ./data/data.yaml\n",
      "------------------------------------------------------------\n",
      "🔍 Running Ultralytics validation for mAP calculation...\n",
      "Ultralytics 8.3.170  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,113,084 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 339.7125.5 MB/s, size: 19.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\KULIAH\\SP-25\\Comvis\\FinalProj\\WebObstacleDetection\\data\\valid\\labels.cache... 251 images, 2 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 16/16 [00:01<00:00, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        251        695      0.812      0.714      0.774       0.53\n",
      "Speed: 0.1ms preprocess, 3.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mAP@0.5: 0.7743\n",
      "✅ mAP@0.5:0.95: 0.5304\n",
      "🔄 Processing images for classification metrics...\n",
      "  Processed 0/251 images\n",
      "  Processed 100/251 images\n",
      "  Processed 200/251 images\n",
      "✅ Processed 251 images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced Classification Report (with mAP@0.5):\n",
      "===========================================================================\n",
      "       Class  Precision     Recall   F1-Score    mAP@0.5    Support\n",
      "---------------------------------------------------------------------------\n",
      "       Mobil       0.52       0.55       0.53     0.5642        248\n",
      "       Motor       0.66       0.80       0.72     0.5957         79\n",
      "       Orang       0.53       0.31       0.39     0.2352        195\n",
      "        Truk       0.61       0.62       0.61     0.7267        172\n",
      "---------------------------------------------------------------------------\n",
      "         All       0.56       0.53       0.53     0.5156        694\n",
      "===========================================================================\n",
      "Overall Accuracy (excluding no-object): 0.5274\n",
      "\n",
      "==================================================\n",
      "OVERALL mAP RESULTS\n",
      "==================================================\n",
      "📊 mAP@0.5 (weighted avg):  0.5156\n",
      "📊 mAP@0.5 (macro avg):     0.5304\n",
      "📊 mAP@0.5:0.95:            0.5304\n",
      "📊 Overall mAP@0.5:         0.7743\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 ============================================================ 🏆\n",
      "🎯 FINAL EVALUATION SUMMARY\n",
      "🏆 ============================================================ 🏆\n",
      "📁 Model: suBest3.pt\n",
      "📊 Dataset: 251 images, 4 classes\n",
      "📈 mAP@0.5:      0.7743 🟢\n",
      "📈 mAP@0.5:0.95:  0.5304 🟢\n",
      "📈 Accuracy:     0.5274 🟡\n",
      "🥇 Best Class:   Truk (mAP: 0.7267)\n",
      "⚠️  Worst Class:  Orang (mAP: 0.2352)\n",
      "🏆 ============================================================ 🏆\n",
      "\n",
      "💾 All results saved to: ./runs/detect/yolov5su_1/\n",
      "📁 Generated files:\n",
      "  - SUM_confusion_matrix.png\n",
      "  - SUM_all_metrics_per_class.png (NEW: includes mAP)\n",
      "  - SUM_mAP_per_class.png\n",
      "  - SUM_enhanced_summary_metrics.png (NEW: with weighted/macro mAP)\n",
      "  - SUM_enhanced_performance_heatmap.png (NEW: with 'All' averages)\n",
      "\n",
      "📂 Full paths:\n",
      "  - ./runs/detect/yolov5su_1/SUM_confusion_matrix.png\n",
      "  - ./runs/detect/yolov5su_1/SUM_all_metrics_per_class.png\n",
      "  - ./runs/detect/yolov5su_1/SUM_mAP_per_class.png\n",
      "  - ./runs/detect/yolov5su_1/SUM_enhanced_summary_metrics.png\n",
      "  - ./runs/detect/yolov5su_1/SUM_enhanced_performance_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    precision_recall_fscore_support, accuracy_score\n",
    ")\n",
    "\n",
    "# ================== CONFIGURATION - EDIT PATHS HERE ==================\n",
    "# Main output directory\n",
    "PATH_UTAMA = \"./runs/detect/yolov5su_1/\"\n",
    "\n",
    "# Individual image filenames (edit these names as needed)\n",
    "GAMBAR_CONFUSION_MATRIX = \"SUM_confusion_matrix.png\"\n",
    "GAMBAR_ALL_METRICS = \"SUM_all_metrics_per_class.png\"  \n",
    "GAMBAR_MAP_PER_CLASS = \"SUM_mAP_per_class.png\"\n",
    "GAMBAR_ENHANCED_SUMMARY = \"SUM_enhanced_summary_metrics.png\"\n",
    "GAMBAR_ENHANCED_HEATMAP = \"SUM_enhanced_performance_heatmap.png\"\n",
    "\n",
    "# Create full paths by joining\n",
    "PATH_CONFUSION_MATRIX = os.path.join(PATH_UTAMA, GAMBAR_CONFUSION_MATRIX)\n",
    "PATH_ALL_METRICS = os.path.join(PATH_UTAMA, GAMBAR_ALL_METRICS)\n",
    "PATH_MAP_PER_CLASS = os.path.join(PATH_UTAMA, GAMBAR_MAP_PER_CLASS)\n",
    "PATH_ENHANCED_SUMMARY = os.path.join(PATH_UTAMA, GAMBAR_ENHANCED_SUMMARY)\n",
    "PATH_ENHANCED_HEATMAP = os.path.join(PATH_UTAMA, GAMBAR_ENHANCED_HEATMAP)\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(PATH_UTAMA, exist_ok=True)\n",
    "\n",
    "# Model configuration\n",
    "MODEL_PATH = \"./runs/detect/yolov5su_1/weights/suBest3.pt\"\n",
    "DATA_YAML_PATH = \"./data/data.yaml\"\n",
    "\n",
    "print(f\"📁 Output directory: {PATH_UTAMA}\")\n",
    "print(f\"🤖 Model: {MODEL_PATH}\")\n",
    "print(f\"📊 Data config: {DATA_YAML_PATH}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ================== LOAD MODEL ==================\n",
    "model = YOLO(MODEL_PATH)  # Using configured model path\n",
    "\n",
    "# ================== LOAD DATASET ==================\n",
    "with open(DATA_YAML_PATH, \"r\") as f:  # Using configured data yaml path\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "\n",
    "class_names = data_yaml[\"names\"]\n",
    "val_path = \"./data/valid/images\"\n",
    "\n",
    "# dukung jpg & png\n",
    "img_files = glob.glob(os.path.join(val_path, \"*.jpg\")) + glob.glob(os.path.join(val_path, \"*.png\"))\n",
    "if len(img_files) == 0:\n",
    "    raise ValueError(f\"Tidak ditemukan gambar di {val_path}\")\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "# ================== EVALUASI MENGGUNAKAN ULTRALYTICS VAL ==================\n",
    "print(\"🔍 Running Ultralytics validation for mAP calculation...\")\n",
    "val_results = model.val(data=DATA_YAML_PATH, verbose=False, plots=False)  # Using configured path\n",
    "\n",
    "# Extract mAP values\n",
    "map_50 = float(val_results.box.map50) if hasattr(val_results.box, 'map50') else 0.0\n",
    "map_50_95 = float(val_results.box.map) if hasattr(val_results.box, 'map') else 0.0\n",
    "maps_per_class = val_results.box.maps if hasattr(val_results.box, 'maps') else [0.0] * len(class_names)\n",
    "\n",
    "# Convert to list if numpy array\n",
    "if hasattr(maps_per_class, 'tolist'):\n",
    "    maps_per_class = maps_per_class.tolist()\n",
    "\n",
    "print(f\"✅ mAP@0.5: {map_50:.4f}\")\n",
    "print(f\"✅ mAP@0.5:0.95: {map_50_95:.4f}\")\n",
    "\n",
    "# ================== LOOP GAMBAR UNTUK CLASSIFICATION METRICS ==================\n",
    "print(\"🔄 Processing images for classification metrics...\")\n",
    "for i, img in enumerate(img_files):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"  Processed {i}/{len(img_files)} images\")\n",
    "    \n",
    "    results = model.predict(img, verbose=False)\n",
    "\n",
    "    preds = []\n",
    "    if len(results[0].boxes) > 0:\n",
    "        preds = results[0].boxes.cls.cpu().numpy().astype(int).tolist()\n",
    "\n",
    "    # cari label txt\n",
    "    label_file = img.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "    gts = []\n",
    "    if os.path.exists(label_file):\n",
    "        with open(label_file, \"r\") as lf:\n",
    "            for line in lf.readlines():\n",
    "                gt_class = int(line.split()[0])\n",
    "                gts.append(gt_class)\n",
    "\n",
    "    # cocokkan prediksi vs ground truth\n",
    "    if len(gts) == 0 and len(preds) > 0:\n",
    "        for p in preds:\n",
    "            y_true.append(-1)\n",
    "            y_pred.append(p)\n",
    "    elif len(preds) == 0 and len(gts) > 0:\n",
    "        for g in gts:\n",
    "            y_true.append(g)\n",
    "            y_pred.append(-1)\n",
    "    else:\n",
    "        for g, p in zip(gts, preds):\n",
    "            y_true.append(g)\n",
    "            y_pred.append(p)\n",
    "\n",
    "        if len(gts) > len(preds):\n",
    "            for g in gts[len(preds):]:\n",
    "                y_true.append(g)\n",
    "                y_pred.append(-1)\n",
    "        elif len(preds) > len(gts):\n",
    "            for p in preds[len(gts):]:\n",
    "                y_true.append(-1)\n",
    "                y_pred.append(p)\n",
    "\n",
    "print(f\"✅ Processed {len(img_files)} images\")\n",
    "\n",
    "# ================== EVALUASI ==================\n",
    "if len(y_true) == 0:\n",
    "    print(\"⚠️ Tidak ada data untuk evaluasi.\")\n",
    "    exit()\n",
    "\n",
    "# Confusion Matrix\n",
    "labels = list(range(len(class_names)))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.savefig(PATH_CONFUSION_MATRIX, dpi=300)  # Using configured path\n",
    "plt.show()\n",
    "\n",
    "# ================== ENHANCED CLASSIFICATION REPORT WITH mAP ==================\n",
    "print(\"\\nEnhanced Classification Report (with mAP@0.5):\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Calculate precision, recall, f1 per class\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true, y_pred, labels=labels, zero_division=0\n",
    ")\n",
    "\n",
    "# Create custom classification report with mAP\n",
    "header = f\"{'Class':>12} {'Precision':>10} {'Recall':>10} {'F1-Score':>10} {'mAP@0.5':>10} {'Support':>10}\"\n",
    "print(header)\n",
    "print(\"-\" * 75)\n",
    "\n",
    "total_support = 0\n",
    "weighted_precision = 0\n",
    "weighted_recall = 0 \n",
    "weighted_f1 = 0\n",
    "weighted_map = 0\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_precision = precision[i]\n",
    "    class_recall = recall[i]\n",
    "    class_f1 = f1[i]\n",
    "    class_map = maps_per_class[i] if i < len(maps_per_class) else 0.0\n",
    "    class_support = np.sum((np.array(y_true) == i) & (np.array(y_true) != -1))\n",
    "    \n",
    "    # Print per-class metrics\n",
    "    print(f\"{class_name:>12} {class_precision:>10.2f} {class_recall:>10.2f} {class_f1:>10.2f} {class_map:>10.4f} {class_support:>10}\")\n",
    "    \n",
    "    # Calculate weighted averages (only for valid predictions)\n",
    "    if class_support > 0:\n",
    "        total_support += class_support\n",
    "        weighted_precision += class_precision * class_support\n",
    "        weighted_recall += class_recall * class_support\n",
    "        weighted_f1 += class_f1 * class_support\n",
    "        weighted_map += class_map * class_support\n",
    "\n",
    "print(\"-\" * 75)\n",
    "\n",
    "# Calculate overall averages\n",
    "if total_support > 0:\n",
    "    avg_precision = weighted_precision / total_support\n",
    "    avg_recall = weighted_recall / total_support\n",
    "    avg_f1 = weighted_f1 / total_support\n",
    "    avg_map = weighted_map / total_support\n",
    "else:\n",
    "    avg_precision = avg_recall = avg_f1 = avg_map = 0.0\n",
    "\n",
    "# Print \"All\" row\n",
    "print(f\"{'All':>12} {avg_precision:>10.2f} {avg_recall:>10.2f} {avg_f1:>10.2f} {avg_map:>10.4f} {total_support:>10}\")\n",
    "\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Accuracy (exclude -1/no object)\n",
    "mask = np.array(y_true) != -1\n",
    "if np.sum(mask) > 0:\n",
    "    acc = accuracy_score(np.array(y_true)[mask], np.array(y_pred)[mask])\n",
    "    print(f\"Overall Accuracy (excluding no-object): {acc:.4f}\")\n",
    "else:\n",
    "    acc = 0.0\n",
    "    print(f\"Overall Accuracy (excluding no-object): {acc:.4f}\")\n",
    "\n",
    "# ================== SUMMARY mAP METRICS ==================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"OVERALL mAP RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"📊 mAP@0.5 (weighted avg):  {avg_map:.4f}\")\n",
    "print(f\"📊 mAP@0.5 (macro avg):     {np.mean(maps_per_class):.4f}\")\n",
    "print(f\"📊 mAP@0.5:0.95:            {map_50_95:.4f}\")\n",
    "print(f\"📊 Overall mAP@0.5:         {map_50:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# ================== GRAFIK METRIK (Enhanced with mAP) ==================\n",
    "precision_calc, recall_calc, f1_calc, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred, labels=labels, zero_division=0\n",
    ")\n",
    "\n",
    "# ================== GRAFIK 1: All Metrics per Class (Including mAP) ==================\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.2\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "bars1 = plt.bar(x - 1.5*width, precision_calc, width, label=\"Precision\", alpha=0.8, color='lightcoral')\n",
    "bars2 = plt.bar(x - 0.5*width, recall_calc, width, label=\"Recall\", alpha=0.8, color='lightgreen')\n",
    "bars3 = plt.bar(x + 0.5*width, f1_calc, width, label=\"F1-score\", alpha=0.8, color='lightsalmon')\n",
    "bars4 = plt.bar(x + 1.5*width, maps_per_class, width, label=\"mAP@0.5\", alpha=0.8, color='skyblue')\n",
    "\n",
    "# Tambahkan angka di atas tiap bar\n",
    "def add_labels_enhanced(bars, values):\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f\"{value:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8, rotation=0\n",
    "        )\n",
    "\n",
    "add_labels_enhanced(bars1, precision_calc)\n",
    "add_labels_enhanced(bars2, recall_calc) \n",
    "add_labels_enhanced(bars3, f1_calc)\n",
    "add_labels_enhanced(bars4, maps_per_class)\n",
    "\n",
    "plt.xticks(x, class_names, rotation=45)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"All Metrics per Class (Precision, Recall, F1-score, mAP@0.5)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(PATH_ALL_METRICS, dpi=300, bbox_inches='tight')  # Using configured path\n",
    "plt.show()\n",
    "\n",
    "# ================== GRAFIK 2: mAP per Class ==================\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars_map = plt.bar(x, maps_per_class, width=0.6, label=\"mAP@0.5\", color='skyblue', alpha=0.8)\n",
    "\n",
    "# Tambahkan angka di atas tiap bar\n",
    "for bar, value in zip(bars_map, maps_per_class):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "        f\"{value:.3f}\", ha=\"center\", va=\"bottom\", fontsize=10, fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.xticks(x, class_names, rotation=45)\n",
    "plt.ylim(0, 1.0)   # sumbu Y fix ke 1.0\n",
    "plt.ylabel(\"mAP@0.5\")\n",
    "plt.title(f\"mAP@0.5 per Class (Overall mAP@0.5: {map_50:.3f})\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(PATH_MAP_PER_CLASS, dpi=300)  # Using configured path\n",
    "plt.show()\n",
    "\n",
    "# ================== GRAFIK 3: Summary Metrics Comparison (Enhanced) ==================\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Enhanced metrics with different mAP calculations\n",
    "all_metrics = ['Precision\\n(Avg)', 'Recall\\n(Avg)', 'F1-Score\\n(Avg)', 'Accuracy', 'mAP@0.5\\n(Weighted)', 'mAP@0.5\\n(Macro)', 'mAP@0.5:0.95']\n",
    "all_values = [\n",
    "    avg_precision, \n",
    "    avg_recall, \n",
    "    avg_f1, \n",
    "    acc, \n",
    "    avg_map,\n",
    "    np.mean(maps_per_class),\n",
    "    map_50_95\n",
    "]\n",
    "colors = ['lightcoral', 'lightgreen', 'lightsalmon', 'gold', 'skyblue', 'lightblue', 'plum']\n",
    "\n",
    "bars_summary = plt.bar(all_metrics, all_values, color=colors, alpha=0.8)\n",
    "\n",
    "# Tambahkan angka di atas tiap bar\n",
    "for bar, value in zip(bars_summary, all_values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "        f\"{value:.3f}\", ha=\"center\", va=\"bottom\", fontsize=10, fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.ylim(0, 1.0)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Enhanced Performance Summary (All Metrics)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(PATH_ENHANCED_SUMMARY, dpi=300, bbox_inches='tight')  # Using configured path\n",
    "plt.show()\n",
    "\n",
    "# ================== GRAFIK 4: Enhanced Performance Heatmap ==================\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create matrix with all metrics per class including mAP\n",
    "metrics_matrix = np.array([\n",
    "    precision_calc,\n",
    "    recall_calc, \n",
    "    f1_calc,\n",
    "    maps_per_class\n",
    "])\n",
    "\n",
    "# Create heatmap\n",
    "ax = sns.heatmap(metrics_matrix, \n",
    "                annot=True, \n",
    "                fmt=\".3f\", \n",
    "                cmap=\"Blues\",\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=['Precision', 'Recall', 'F1-Score', 'mAP@0.5'],\n",
    "                cbar_kws={'label': 'Score'})\n",
    "\n",
    "plt.title(\"Enhanced Per-Class Performance Heatmap (Including mAP@0.5)\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "\n",
    "# Add \"All\" column for averages\n",
    "all_column = [avg_precision, avg_recall, avg_f1, avg_map]\n",
    "for i, value in enumerate(all_column):\n",
    "    ax.text(len(class_names) + 0.5, i + 0.5, f\"All\\n{value:.3f}\", \n",
    "           ha='center', va='center', fontsize=11, fontweight='bold',\n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(PATH_ENHANCED_HEATMAP, dpi=300, bbox_inches='tight')  # Using configured path\n",
    "plt.show()\n",
    "\n",
    "# ================== FINAL SUMMARY ==================\n",
    "print(f\"\\n🏆 {'='*60} 🏆\")\n",
    "print(\"🎯 FINAL EVALUATION SUMMARY\")\n",
    "print(f\"🏆 {'='*60} 🏆\")\n",
    "print(f\"📁 Model: {os.path.basename(MODEL_PATH)}\")\n",
    "print(f\"📊 Dataset: {len(img_files)} images, {len(class_names)} classes\")\n",
    "print(f\"📈 mAP@0.5:      {map_50:.4f} {'🟢' if map_50 > 0.5 else '🟡' if map_50 > 0.3 else '🔴'}\")\n",
    "print(f\"📈 mAP@0.5:0.95:  {map_50_95:.4f} {'🟢' if map_50_95 > 0.3 else '🟡' if map_50_95 > 0.2 else '🔴'}\")\n",
    "print(f\"📈 Accuracy:     {acc:.4f} {'🟢' if acc > 0.7 else '🟡' if acc > 0.5 else '🔴'}\")\n",
    "\n",
    "# Show best and worst performing classes\n",
    "class_performance = list(zip(class_names, maps_per_class))\n",
    "class_performance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"🥇 Best Class:   {class_performance[0][0]} (mAP: {class_performance[0][1]:.4f})\")\n",
    "print(f\"⚠️  Worst Class:  {class_performance[-1][0]} (mAP: {class_performance[-1][1]:.4f})\")\n",
    "print(f\"🏆 {'='*60} 🏆\")\n",
    "\n",
    "print(f\"\\n💾 All results saved to: {PATH_UTAMA}\")\n",
    "print(\"📁 Generated files:\")\n",
    "print(f\"  - {GAMBAR_CONFUSION_MATRIX}\")\n",
    "print(f\"  - {GAMBAR_ALL_METRICS} (NEW: includes mAP)\")\n",
    "print(f\"  - {GAMBAR_MAP_PER_CLASS}\")\n",
    "print(f\"  - {GAMBAR_ENHANCED_SUMMARY} (NEW: with weighted/macro mAP)\")\n",
    "print(f\"  - {GAMBAR_ENHANCED_HEATMAP} (NEW: with 'All' averages)\")\n",
    "\n",
    "print(f\"\\n📂 Full paths:\")\n",
    "print(f\"  - {PATH_CONFUSION_MATRIX}\")\n",
    "print(f\"  - {PATH_ALL_METRICS}\")\n",
    "print(f\"  - {PATH_MAP_PER_CLASS}\")\n",
    "print(f\"  - {PATH_ENHANCED_SUMMARY}\")\n",
    "print(f\"  - {PATH_ENHANCED_HEATMAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb357e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PRINT METRICS =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Akses metrics dari hasil validasi\n",
    "metrics = val_results.results_dict\n",
    "\n",
    "# Print Box metrics (untuk detection)\n",
    "def safe_format(value, format_str=\".4f\"):\n",
    "    \"\"\"Safely format numeric values, return 'N/A' if not a number\"\"\"\n",
    "    if isinstance(value, (int, float)) and not isinstance(value, str):\n",
    "        return f\"{value:{format_str}}\"\n",
    "    return str(value)\n",
    "\n",
    "precision = metrics.get('metrics/precision(B)', 'N/A')\n",
    "recall = metrics.get('metrics/recall(B)', 'N/A') \n",
    "map50 = metrics.get('metrics/mAP50(B)', 'N/A')\n",
    "map50_95 = metrics.get('metrics/mAP50-95(B)', 'N/A')\n",
    "\n",
    "print(f\"Precision (P): {safe_format(precision)}\")\n",
    "print(f\"Recall (R): {safe_format(recall)}\")\n",
    "print(f\"mAP50 (AP@0.5): {safe_format(map50)}\")\n",
    "print(f\"mAP50-95 (AP@0.5:0.95): {safe_format(map50_95)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39334748",
   "metadata": {},
   "source": [
    "#### Manual Evaluation (Classification Metrics)\n",
    "**This is the evaluation metrics results for the:**\n",
    "> **Accuracy**\\\n",
    "> **Precision**\\\n",
    "> **Recall**\\\n",
    "> **F1-Score**\\\n",
    "> **Support**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b8c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MANUAL EVALUATION ON TEST SET\n",
      "==================================================\n",
      "✅ Menggunakan test set: ./data/test/images\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478019954685370994_jpg.rf.267b411a4ff9ba298106dab1ba886e4f.jpg: 320x320 3 Mobils, 38.8ms\n",
      "image 2/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478019963682173845_jpg.rf.bdafc1aaf7c2d4e52e52963eb5983e7f.jpg: 320x320 4 Mobils, 38.7ms\n",
      "image 3/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478019974179606198_jpg.rf.caf5fc8ab4be24cc76800edc7041b0ce.jpg: 320x320 4 Mobils, 1 Orang, 38.4ms\n",
      "image 4/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478731977436292831_jpg.rf.d9c67a94eff2a9929759d6a3ab9eea26.jpg: 320x320 2 Mobils, 2 Truks, 38.3ms\n",
      "image 5/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478732067475105076_jpg.rf.e5eceb23c1b4e480264967b654896678.jpg: 320x320 4 Mobils, 1 Truk, 16.9ms\n",
      "image 6/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478732069768111040_jpg.rf.cd004bd8dcc2a53ba2d5073e3b6cb508.jpg: 320x320 2 Mobils, 4 Truks, 5.3ms\n",
      "image 7/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478732150054933348_jpg.rf.61b202ea7c801601715c2a576ae3ffd7.jpg: 320x320 4 Mobils, 2 Truks, 6.2ms\n",
      "image 8/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478732640957558254_jpg.rf.8f407025fd216ca845d499ad38b8c979.jpg: 320x320 2 Mobils, 2 Truks, 5.8ms\n",
      "image 9/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478732642105203429_jpg.rf.3dceccfd4e002c7832d21c6b7efb8661.jpg: 320x320 1 Mobil, 2 Truks, 8.4ms\n",
      "image 10/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478732710348678903_jpg.rf.24cd5cca5ef476330076ed7ec9a99b7c.jpg: 320x320 3 Mobils, 1 Truk, 5.6ms\n",
      "image 11/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897087183348620_jpg.rf.4fe99362acd28863bcdc7934887920eb.jpg: 320x320 6 Mobils, 2 Truks, 5.6ms\n",
      "image 12/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897087754949352_jpg.rf.18ba2dc30d72ce6f02f4453d2bb0c394.jpg: 320x320 6 Mobils, 2 Truks, 5.5ms\n",
      "image 13/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897111178185327_jpg.rf.ab82c3a8a6a68160a16e848824f05443.jpg: 320x320 4 Mobils, 1 Orang, 5.6ms\n",
      "image 14/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897114605643420_jpg.rf.326b3365a326989bd4f6b69cee6b0703.jpg: 320x320 4 Mobils, 2 Orangs, 1 Truk, 5.8ms\n",
      "image 15/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897125459992395_jpg.rf.26600bbe80ca276ce32caa79029d5c54.jpg: 320x320 8 Mobils, 1 Truk, 5.7ms\n",
      "image 16/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897126603038383_jpg.rf.1d32addcd48a530cf396da884f87b5d2.jpg: 320x320 5 Mobils, 2 Truks, 11.8ms\n",
      "image 17/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897147740427833_jpg.rf.1f848dbbe992a17bdb78a742cd804684.jpg: 320x320 4 Mobils, 1 Orang, 1 Truk, 9.5ms\n",
      "image 18/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897154024479125_jpg.rf.abcae4833adfab55ed097aae9b9e6d06.jpg: 320x320 4 Mobils, 2 Truks, 5.6ms\n",
      "image 19/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897156880988821_jpg.rf.1bc7928c8e1fa7e8cf31789aefdec350.jpg: 320x320 4 Mobils, 5.9ms\n",
      "image 20/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897159167206096_jpg.rf.370e812a749648505af8bf5677b11c08.jpg: 320x320 5 Mobils, 6.1ms\n",
      "image 21/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897300847486205_jpg.rf.f46b0eb0d0a8696e98b714467f1cd16a.jpg: 320x320 5 Mobils, 2 Orangs, 1 Truk, 11.8ms\n",
      "image 22/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897302560667650_jpg.rf.a848b60039455fd173c9528841ccfded.jpg: 320x320 6 Mobils, 4 Orangs, 1 Truk, 6.3ms\n",
      "image 23/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897728171236733_jpg.rf.df76526d1f46dc44715d95b51775b599.jpg: 320x320 4 Mobils, 5.9ms\n",
      "image 24/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897806438179720_jpg.rf.82f9495ef9571444424e670ebe5c3a9a.jpg: 320x320 3 Mobils, 11.5ms\n",
      "image 25/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897821291730515_jpg.rf.9b1ad7ca4e71e4580d3310e72597f553.jpg: 320x320 3 Mobils, 5.7ms\n",
      "image 26/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897839001463453_jpg.rf.b61503d4c8924dc66fe267601c040587.jpg: 320x320 2 Mobils, 3 Orangs, 3 Truks, 8.5ms\n",
      "image 27/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897842429008508_jpg.rf.c321aec57e89afaaebd742778d939cff.jpg: 320x320 5 Mobils, 6 Orangs, 2 Truks, 6.0ms\n",
      "image 28/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897844713874413_jpg.rf.55830bf3f87bab64d31cd0ad87b376bd.jpg: 320x320 3 Mobils, 10 Orangs, 1 Truk, 7.1ms\n",
      "image 29/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897855568054263_jpg.rf.4d232cadd00c2022d4dea0d9ceab0397.jpg: 320x320 3 Mobils, 4 Orangs, 2 Truks, 12.1ms\n",
      "image 30/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897856140609864_jpg.rf.b65f8e25118e37f8784ba6c621177f82.jpg: 320x320 4 Mobils, 3 Orangs, 2 Truks, 12.3ms\n",
      "image 31/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897858996349508_jpg.rf.f2474d2991a823ebd3e19c7bd20c319e.jpg: 320x320 5 Mobils, 1 Orang, 2 Truks, 7.0ms\n",
      "image 32/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897861853325897_jpg.rf.4f5b52c21aa6fabb3d909cf526db532c.jpg: 320x320 4 Mobils, 2 Orangs, 2 Truks, 6.7ms\n",
      "image 33/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897867565712186_jpg.rf.ee4aaf9d4e56d5760bc96410544f7d02.jpg: 320x320 4 Mobils, 2 Orangs, 2 Truks, 6.3ms\n",
      "image 34/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897874422308532_jpg.rf.52b3b74267dcc570977bb8bc2bd3fc90.jpg: 320x320 3 Mobils, 1 Orang, 2 Truks, 5.9ms\n",
      "image 35/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897877277538473_jpg.rf.d44e9deaf06ec2371c74f3f85f31e85d.jpg: 320x320 4 Mobils, 1 Orang, 2 Truks, 11.8ms\n",
      "image 36/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897877848943728_jpg.rf.286fe36f86a94d69ab9c49e1d4dd3f38.jpg: 320x320 4 Mobils, 1 Orang, 2 Truks, 5.3ms\n",
      "image 37/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897878991762809_jpg.rf.8f0c3af38ccbdaa8b6c1cd705660fc0e.jpg: 320x320 3 Mobils, 2 Orangs, 2 Truks, 5.4ms\n",
      "image 38/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897933264540671_jpg.rf.d83c7a5acffc79ac65a483ee92c96e76.jpg: 320x320 5 Mobils, 2 Orangs, 1 Truk, 11.0ms\n",
      "image 39/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897935548845338_jpg.rf.65df747d751607fb266f5e87ff2605e6.jpg: 320x320 5 Mobils, 3 Orangs, 1 Truk, 5.9ms\n",
      "image 40/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897936692871206_jpg.rf.62884c8e4006c1513908cfa3381db0da.jpg: 320x320 7 Mobils, 1 Orang, 1 Truk, 5.5ms\n",
      "image 41/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897940119790548_jpg.rf.fb7637dee79f8d1b204a34a7f1ffc054.jpg: 320x320 5 Mobils, 5 Orangs, 1 Truk, 5.8ms\n",
      "image 42/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897943547200651_jpg.rf.817ae14b719d3b1b5f7a5226ea626eb0.jpg: 320x320 4 Mobils, 1 Orang, 1 Truk, 5.7ms\n",
      "image 43/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897950973638158_jpg.rf.0dd0664631003d49c0226d7e9759abe7.jpg: 320x320 3 Mobils, 1 Truk, 5.2ms\n",
      "image 44/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897954974426629_jpg.rf.dd0d6e031ee59192127d40cdfaf19a48.jpg: 320x320 1 Mobil, 1 Orang, 2 Truks, 5.8ms\n",
      "image 45/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897956687726972_jpg.rf.9581b5d9def494bc4145254d8e0e63ff.jpg: 320x320 2 Mobils, 3 Orangs, 1 Truk, 7.1ms\n",
      "image 46/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897957829946287_jpg.rf.208c19db78261610b4b7825479c39fc1.jpg: 320x320 1 Mobil, 1 Orang, 5.4ms\n",
      "image 47/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478897989822531570_jpg.rf.be69ea7a985308e79e46de4e6dbc9da0.jpg: 320x320 9 Mobils, 1 Orang, 1 Truk, 6.3ms\n",
      "image 48/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478898012102444948_jpg.rf.0a74ca69fbfe583a6b6af18b7899f2e9.jpg: 320x320 6 Mobils, 1 Truk, 5.9ms\n",
      "image 49/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478899660272776154_jpg.rf.3fe053aadce054871ce32defc35d3b8f.jpg: 320x320 5 Mobils, 1 Orang, 5.6ms\n",
      "image 50/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\1478900394951031832_jpg.rf.b652322a568826d05d99c3e6a259970b.jpg: 320x320 (no detections), 5.5ms\n",
      "image 51/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_00_22_16_Still005_jpg.rf.426674ad120ca102c303086bd2e4cb39.jpg: 320x320 1 Mobil, 3 Motors, 6.2ms\n",
      "image 52/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_00_23_06_Still006_jpg.rf.78758a6496baad2512dc8b39a4633b15.jpg: 320x320 1 Mobil, 2 Motors, 5.6ms\n",
      "image 53/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_01_02_00_Still018_jpg.rf.d0ec2624fdf4bd30aa6fb9a568456fbe.jpg: 320x320 1 Mobil, 6 Motors, 7.4ms\n",
      "image 54/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_01_17_01_Still023_jpg.rf.8529782e128954fe020d218c0087cedf.jpg: 320x320 1 Mobil, 2 Motors, 1 Truk, 5.9ms\n",
      "image 55/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_01_33_15_Still030_jpg.rf.e967b0c07c7cd634cbc636251eb3d70d.jpg: 320x320 1 Motor, 1 Truk, 5.6ms\n",
      "image 56/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_01_47_00_Still039_jpg.rf.b99ed2579bba3255b13e4ecfb8746050.jpg: 320x320 2 Motors, 6.1ms\n",
      "image 57/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_06_15_09_Still098_jpg.rf.e5948098b3bfda4f133422c3322d04b6.jpg: 320x320 1 Mobil, 3 Motors, 8.8ms\n",
      "image 58/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_11_20_09_Still076_jpg.rf.b518240fa3b74c13d98e95d890f6000c.jpg: 320x320 1 Mobil, 4 Motors, 9.8ms\n",
      "image 59/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_11_21_11_Still077_jpg.rf.044e5d9230a1c60c5a672f94fb45cddf.jpg: 320x320 2 Mobils, 4 Motors, 5.5ms\n",
      "image 60/60 d:\\KULIAH\\SP-25\\Comvis\\FinalProj\\TrainProgram\\data\\test\\images\\VID_20250813_143951_00_11_44_25_Still084_jpg.rf.4ba47275bc87a92dd50fd0b92e196bf8.jpg: 320x320 3 Mobils, 3 Motors, 5.9ms\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 320)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "✅ Inference berhasil pada 60 gambar\n",
      "\n",
      "🔍 Processing 60 hasil deteksi...\n",
      "✅ Berhasil memproses: 60 file\n",
      "⚠️  File yang dilewati: 0 file\n",
      "📊 Total samples: 365 ground truth, 365 predictions\n",
      "\n",
      "📈 COMPUTING METRICS...\n",
      "Ground Truth samples: 365\n",
      "Prediction samples: 365\n",
      "\n",
      "🎯 OVERALL METRICS:\n",
      "Accuracy: 0.4795\n",
      "Precision (weighted avg): 0.5805\n",
      "Recall (weighted avg): 0.4795\n",
      "F1-Score (weighted avg): 0.5172\n",
      "\n",
      "📋 DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Missed       0.00      0.00      0.00         0\n",
      "       Mobil       0.62      0.57      0.59       195\n",
      "       Motor       0.67      0.69      0.68        26\n",
      "       Orang       0.67      0.34      0.45        87\n",
      "        Truk       0.29      0.28      0.28        57\n",
      "\n",
      "    accuracy                           0.48       365\n",
      "   macro avg       0.45      0.38      0.40       365\n",
      "weighted avg       0.58      0.48      0.52       365\n",
      "\n",
      "\n",
      "📊 PER-CLASS DETAILED METRICS:\n",
      "\n",
      "🏷️  Mobil (Class 0):\n",
      "   Precision: 0.6167\n",
      "   Recall: 0.5692\n",
      "   F1-Score: 0.5920\n",
      "   Support: 195\n",
      "\n",
      "🏷️  Motor (Class 1):\n",
      "   Precision: 0.6667\n",
      "   Recall: 0.6923\n",
      "   F1-Score: 0.6792\n",
      "   Support: 26\n",
      "\n",
      "🏷️  Orang (Class 2):\n",
      "   Precision: 0.6667\n",
      "   Recall: 0.3448\n",
      "   F1-Score: 0.4545\n",
      "   Support: 87\n",
      "\n",
      "🏷️  Truk (Class 3):\n",
      "   Precision: 0.2857\n",
      "   Recall: 0.2807\n",
      "   F1-Score: 0.2832\n",
      "   Support: 57\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ===== MANUAL EVALUATION WITH ERROR HANDLING =====\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MANUAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if test directories exist\n",
    "test_images_dir = \"./data/test/images\"\n",
    "test_labels_dir = \"./data/test/labels\"\n",
    "\n",
    "if not os.path.exists(test_images_dir):\n",
    "    print(f\"❌ Test images directory tidak ditemukan: {test_images_dir}\")\n",
    "    print(\"💡 Menggunakan validation set sebagai alternatif...\")\n",
    "    test_images_dir = \"./data/valid/images\"\n",
    "    test_labels_dir = \"./data/valid/labels\"\n",
    "\n",
    "if not os.path.exists(test_images_dir):\n",
    "    print(f\"❌ Validation images directory juga tidak ditemukan: {test_images_dir}\")\n",
    "    print(\"🔍 Struktur dataset Anda:\")\n",
    "    for root, dirs, files in os.walk(\"./data\"):\n",
    "        level = root.replace(\"./data\", \"\").count(os.sep)\n",
    "        indent = \" \" * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = \" \" * 2 * (level + 1)\n",
    "        for file in files[:5]:  # Show first 5 files\n",
    "            print(f\"{subindent}{file}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{subindent}... dan {len(files)-5} file lainnya\")\n",
    "else:\n",
    "    print(f\"✅ Menggunakan test set: {test_images_dir}\")\n",
    "    \n",
    "    # Run inference on test set\n",
    "    try:\n",
    "        test_results = best_model(test_images_dir, save=True, conf=0.25)\n",
    "        print(f\"✅ Inference berhasil pada {len(test_results)} gambar\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saat inference: {e}\")\n",
    "        test_results = []\n",
    "\n",
    "    # Improved function untuk extract labels dan predictions\n",
    "    def extract_labels_and_predictions_improved(results, gt_dir):\n",
    "        \"\"\"\n",
    "        Extract ground truth dan predictions dengan error handling yang lebih baik\n",
    "        \"\"\"\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        processed_files = 0\n",
    "        skipped_files = 0\n",
    "        \n",
    "        print(f\"\\n🔍 Processing {len(results)} hasil deteksi...\")\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            try:\n",
    "                # Get image filename\n",
    "                img_path = result.path if hasattr(result, 'path') else str(result.save_dir / f\"image_{i}.jpg\")\n",
    "                img_name = os.path.basename(img_path)\n",
    "                base_name = os.path.splitext(img_name)[0]\n",
    "                \n",
    "                # Load ground truth\n",
    "                gt_file = os.path.join(gt_dir, f\"{base_name}.txt\")\n",
    "                \n",
    "                if os.path.exists(gt_file):\n",
    "                    with open(gt_file, 'r') as f:\n",
    "                        gt_lines = f.readlines()\n",
    "                    \n",
    "                    gt_classes = []\n",
    "                    pred_classes = []\n",
    "                    \n",
    "                    # Extract ground truth classes\n",
    "                    for line in gt_lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if parts and len(parts) >= 5:  # Valid YOLO format\n",
    "                            gt_classes.append(int(parts[0]))\n",
    "                    \n",
    "                    # Extract predictions\n",
    "                    if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                        for cls in result.boxes.cls:\n",
    "                            pred_classes.append(int(cls.item()))\n",
    "                    \n",
    "                    # Handle case: ada ground truth tapi tidak ada prediksi\n",
    "                    if len(gt_classes) > len(pred_classes):\n",
    "                        # Tambahkan \"missed detection\" sebagai class -1\n",
    "                        pred_classes.extend([-1] * (len(gt_classes) - len(pred_classes)))\n",
    "                    \n",
    "                    # Handle case: ada prediksi tapi lebih banyak dari ground truth  \n",
    "                    elif len(pred_classes) > len(gt_classes):\n",
    "                        # Ambil prediksi dengan confidence tertinggi sebanyak ground truth\n",
    "                        if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "                            # Sort by confidence dan ambil top-k\n",
    "                            confidences = result.boxes.conf.cpu().numpy()\n",
    "                            sorted_indices = confidences.argsort()[::-1]  # Descending\n",
    "                            \n",
    "                            pred_classes_filtered = []\n",
    "                            for idx in sorted_indices[:len(gt_classes)]:\n",
    "                                pred_classes_filtered.append(int(result.boxes.cls[idx].item()))\n",
    "                            pred_classes = pred_classes_filtered\n",
    "                    \n",
    "                    # Pastikan jumlah sama\n",
    "                    min_len = min(len(gt_classes), len(pred_classes))\n",
    "                    if min_len > 0:\n",
    "                        y_true.extend(gt_classes[:min_len])\n",
    "                        y_pred.extend(pred_classes[:min_len])\n",
    "                        processed_files += 1\n",
    "                    else:\n",
    "                        skipped_files += 1\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"⚠️  Label file tidak ditemukan: {gt_file}\")\n",
    "                    skipped_files += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing file {i}: {e}\")\n",
    "                skipped_files += 1\n",
    "                continue\n",
    "        \n",
    "        print(f\"✅ Berhasil memproses: {processed_files} file\")\n",
    "        print(f\"⚠️  File yang dilewati: {skipped_files} file\")\n",
    "        print(f\"📊 Total samples: {len(y_true)} ground truth, {len(y_pred)} predictions\")\n",
    "        \n",
    "        return y_true, y_pred\n",
    "\n",
    "    # Jalankan ekstraksi dengan improved function\n",
    "    if os.path.exists(test_labels_dir) and len(test_results) > 0:\n",
    "        y_true, y_pred = extract_labels_and_predictions_improved(test_results, test_labels_dir)\n",
    "        \n",
    "        if len(y_true) > 0 and len(y_pred) > 0 and len(y_true) == len(y_pred):\n",
    "            print(f\"\\n📈 COMPUTING METRICS...\")\n",
    "            print(f\"Ground Truth samples: {len(y_true)}\")\n",
    "            print(f\"Prediction samples: {len(y_pred)}\")\n",
    "            \n",
    "            # Compute overall metrics\n",
    "            try:\n",
    "                precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                    y_true, y_pred, average='weighted', zero_division=0\n",
    "                )\n",
    "                accuracy = accuracy_score(y_true, y_pred)\n",
    "                \n",
    "                print(f\"\\n🎯 OVERALL METRICS:\")\n",
    "                print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"Precision (weighted avg): {precision:.4f}\")\n",
    "                print(f\"Recall (weighted avg): {recall:.4f}\")\n",
    "                print(f\"F1-Score (weighted avg): {f1:.4f}\")\n",
    "                \n",
    "                # Detailed classification report\n",
    "                print(f\"\\n📋 DETAILED CLASSIFICATION REPORT:\")\n",
    "                unique_classes = sorted(set(y_true + y_pred))\n",
    "                class_names = []\n",
    "                \n",
    "                for cls in unique_classes:\n",
    "                    if cls == -1:\n",
    "                        class_names.append(\"Missed\")\n",
    "                    elif cls in best_model.names:\n",
    "                        class_names.append(best_model.names[cls])\n",
    "                    else:\n",
    "                        class_names.append(f\"Class_{cls}\")\n",
    "                \n",
    "                report = classification_report(\n",
    "                    y_true, y_pred, \n",
    "                    labels=unique_classes,\n",
    "                    target_names=class_names,\n",
    "                    zero_division=0\n",
    "                )\n",
    "                print(report)\n",
    "                \n",
    "                # Per-class detailed metrics\n",
    "                precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
    "                    y_true, y_pred, labels=unique_classes, average=None, zero_division=0\n",
    "                )\n",
    "                \n",
    "                print(f\"\\n📊 PER-CLASS DETAILED METRICS:\")\n",
    "                for i, cls in enumerate(unique_classes):\n",
    "                    if cls != -1:  # Skip missed detections\n",
    "                        class_name = best_model.names.get(cls, f\"Class_{cls}\")\n",
    "                        print(f\"\\n🏷️  {class_name} (Class {cls}):\")\n",
    "                        print(f\"   Precision: {precision_per_class[i]:.4f}\")\n",
    "                        print(f\"   Recall: {recall_per_class[i]:.4f}\")\n",
    "                        print(f\"   F1-Score: {f1_per_class[i]:.4f}\")\n",
    "                        print(f\"   Support: {support_per_class[i]}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error computing metrics: {e}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"❌ Mismatch dalam data:\")\n",
    "            print(f\"   Ground Truth: {len(y_true)} samples\")\n",
    "            print(f\"   Predictions: {len(y_pred)} samples\")\n",
    "            \n",
    "            if len(y_true) == 0:\n",
    "                print(\"💡 Tidak ada ground truth ditemukan. Periksa format file label.\")\n",
    "            if len(y_pred) == 0:\n",
    "                print(\"💡 Tidak ada prediksi ditemukan. Model mungkin tidak mendeteksi objek.\")\n",
    "    else:\n",
    "        if not os.path.exists(test_labels_dir):\n",
    "            print(f\"❌ Test labels directory tidak ditemukan: {test_labels_dir}\")\n",
    "        if len(test_results) == 0:\n",
    "            print(f\"❌ Tidak ada hasil deteksi dari model\")\n",
    "        \n",
    "        print(f\"\\n💡 Alternatif: Gunakan metrics dari validation yang sudah ada:\")\n",
    "        print(f\"   mAP50: {val_results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "        print(f\"   mAP50-95: {val_results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
